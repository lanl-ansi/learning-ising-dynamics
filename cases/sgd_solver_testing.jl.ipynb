{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solvers' Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Any,1}:\n",
       " \"/home/local/julia/julia-d386e40c17/local/share/julia/site/v0.6\"\n",
       " \"/home/local/julia/julia-d386e40c17/share/julia/site/v0.6\"      \n",
       " \"../src/\"                                                       "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add locations of modules\n",
    "push!(LOAD_PATH, \"../src/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /home/local/.julia/lib/v0.6/GraphicalModelLearning.ji for module GraphicalModelLearning.\n",
      "\u001b[39m\n",
      "WARNING: deprecated syntax \"inner constructor FactorGraph(...) around /home/local/Research/Code/GraphicalModelLearning.jl/src/models.jl:13\".\n",
      "Use \"FactorGraph{T}(...) where T\" instead.\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36massuming spin alphabet\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing Glauber dynamics v1 to generate samples\n",
      "\u001b[39mWARNING: using StatsBase.sample in module Main conflicts with an existing identifier.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8×4 Array{Int64,2}:\n",
       " 1309  -1  -1  -1\n",
       "  820  -1  -1   1\n",
       " 1306   1   1   1\n",
       "  182  -1   1  -1\n",
       "  848   1   1  -1\n",
       "  180   1  -1   1\n",
       "  180  -1   1   1\n",
       "  176   1  -1  -1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using GraphicalModelLearning\n",
    "\n",
    "srand(0)\n",
    "\n",
    "# Sample considering a simple factor graph\n",
    "model = FactorGraph([0.0 0.9 0.1; 0.9 0.0 0.1; 0.1 0.1 0.0])\n",
    "#model = FactorGraph([0.4 0.9 0.1; 0.9 0.4 0.1; 0.1 0.1 0.4])\n",
    "samples1 = sample(model, 5000)\n",
    "\n",
    "# Sample using the Gibbs Sampler\n",
    "n_samples = 100000\n",
    "samples_time_series = gibbs_sampling(model, n_samples)\n",
    "\n",
    "# Every mth sample after burn in (Determining when burn-in happens?)\n",
    "t_burn_in = 50000\n",
    "m_samples = 10\n",
    "\n",
    "samples_iid = samples_time_series[t_burn_in:m_samples:n_samples,:]\n",
    "\n",
    "# Compare samples against those produced by direct method\n",
    "using StatsBase\n",
    "raw_binning = countmap(samples_iid)\n",
    "samples2 = [ vcat(raw_binning[i], 2*digits(i, 2, model.varible_count)-1) for i in keys(raw_binning)]\n",
    "samples2 = hcat(samples2...)'\n",
    "\n",
    "# Other trends to check samples after a long time are decorrelated and belong to the stationary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 0.261748 \n",
       " 0.163967 \n",
       " 0.261148 \n",
       " 0.0363927\n",
       " 0.169566 \n",
       " 0.0359928\n",
       " 0.0359928\n",
       " 0.035193 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples2[:,1]/sum(samples2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 0.2614\n",
       " 0.1668\n",
       " 0.2532\n",
       " 0.0362\n",
       " 0.1786\n",
       " 0.0354\n",
       " 0.0348\n",
       " 0.0336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples1[:,1]/sum(samples1[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning on iid samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "  8.007609 seconds (5.18 M allocations: 260.489 MiB, 1.36% gc time)\n",
      "  0.019208 seconds (5.27 k allocations: 363.656 KiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RISE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.188973 seconds (241.78 M allocations: 4.701 GiB, 6.96% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RISE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.710961 seconds (241.96 M allocations: 4.700 GiB, 7.13% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RPLE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.602876 seconds (231.20 M allocations: 4.416 GiB, 6.86% gc time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RPLE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.196218 seconds (100.02 M allocations: 1.909 GiB, 7.08% gc time)\n",
      "[-0.00385463 0.880962 0.0986432; 0.880962 0.00991948 0.0762026; 0.0986432 0.0762026 -0.0209155]\n",
      "[-0.000826041 0.863831 0.104378; 0.863831 0.00735092 0.0961333; 0.104378 0.0961333 -0.0071306]\n",
      "[-0.000286178 0.87706 0.101103; 0.87706 0.00230491 0.0761805; 0.101103 0.0761805 -0.00869534]\n",
      "[0.000213814 0.861309 0.107809; 0.861309 0.000511856 0.0961263; 0.107809 0.0961263 -0.00120892]\n",
      "[-0.00423124 0.886045 0.105687; 0.886045 0.000581257 0.0769122; 0.105687 0.0769122 -0.0153581]\n",
      "[-0.0034631 0.862953 0.109057; 0.862953 -0.000414161 0.0969086; 0.109057 0.0969086 -3.84933e-5]\n"
     ]
    }
   ],
   "source": [
    "# Can the FactorGraph be recovered?\n",
    "@time learned1 = learn(samples1)\n",
    "@time learned2 = learn(samples2)\n",
    "\n",
    "@time learned_sgd_rise1 = learn_sgd(samples1)\n",
    "@time learned_sgd_rise2 = learn_sgd(samples2)\n",
    "\n",
    "@time learned_sgd_rple1 = learn_sgd(samples1, RPLE())\n",
    "@time learned_sgd_rple2 = learn_sgd(samples2, RPLE())\n",
    "\n",
    "println(learned1)\n",
    "println(learned2)\n",
    "\n",
    "println(learned_sgd_rise1)\n",
    "println(learned_sgd_rise2)\n",
    "\n",
    "println(learned_sgd_rple1)\n",
    "println(learned_sgd_rple2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning on correlated samples -- T-regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36massuming spin alphabet\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing Glauber dynamics v1 to generate T-regime samples\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done sampling"
     ]
    }
   ],
   "source": [
    "using GraphicalModelLearning\n",
    "\n",
    "srand(0)\n",
    "\n",
    "# Define Graphical Model\n",
    "model = FactorGraph([0.0 0.9 0.1; 0.9 0.0 0.1; 0.1 0.1 0.0])\n",
    "#model = FactorGraph([0.4 0.9 0.1; 0.9 0.4 0.1; 0.1 0.1 0.4])\n",
    "\n",
    "n_samples = 5000\n",
    "# Plain sampling\n",
    "samples1 = sample(model, n_samples)\n",
    "\n",
    "# Gibbs Samples\n",
    "samples_T, samples_mixed = gibbs_sampling(model, n_samples, T_regime())\n",
    "#gibbs_output = gibbs_sampling(model, n_samples, T_regime())\n",
    "#samples_T = gibbs_output[1]\n",
    "#samples_mixed = gibbs_output[2]\n",
    "print(\"Done sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×7 Array{Int64,2}:\n",
       "   50   1  -1  -1  -1  -1  -1\n",
       "   55   1   1   1   1  -1   1\n",
       "   47  -1   1   1  -1   1   1\n",
       "  175  -1  -1  -1  -1  -1   1\n",
       "   27  -1   1  -1  -1   1   1\n",
       "   52  -1   1  -1  -1  -1  -1\n",
       "   46  -1  -1  -1  -1   1  -1\n",
       "   55  -1   1   1   1   1   1\n",
       "   45   1   1  -1   1  -1  -1\n",
       " 1038  -1  -1  -1  -1  -1  -1\n",
       "   67   1  -1  -1   1  -1  -1\n",
       "   60   1  -1  -1   1   1  -1\n",
       "   39  -1   1  -1   1   1  -1\n",
       "    ⋮                   ⋮    \n",
       "   54   1  -1   1  -1  -1   1\n",
       "   48   1  -1   1   1   1   1\n",
       "   47  -1   1   1  -1  -1   1\n",
       "   57   1  -1   1   1  -1   1\n",
       "  929   1   1   1   1   1   1\n",
       "   30   1  -1   1   1  -1  -1\n",
       "  175   1   1   1   1   1  -1\n",
       "  614   1   1  -1   1   1  -1\n",
       "  566  -1  -1   1  -1  -1   1\n",
       "   29   1  -1  -1   1  -1   1\n",
       "   45  -1  -1   1  -1   1   1\n",
       "   46  -1   1  -1  -1   1  -1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×4 Array{Int64,2}:\n",
       " 1323  -1  -1  -1\n",
       "  842  -1  -1   1\n",
       " 1214   1   1   1\n",
       "  164  -1   1  -1\n",
       "  888   1   1  -1\n",
       "  189   1  -1   1\n",
       "  174  -1   1   1\n",
       "  206   1  -1  -1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "  8.807619 seconds (5.15 M allocations: 259.367 MiB, 1.07% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.031891    0.85722     0.0618882\n",
       " 0.85722    -0.0458952   0.0975106\n",
       " 0.0618882   0.0975106  -0.0304779"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned3 = learn_glauber_dynamics(samples_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RISE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.998540 seconds (12.40 M allocations: 232.713 MiB, 4.54% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.075218    0.820355    0.0707643\n",
       "  0.820355   -0.0373161   0.126903 \n",
       "  0.0707643   0.126903   -0.0495768"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned4 = learn_glauber_dynamics_sgd(samples_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RISE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.074771 seconds (118.32 M allocations: 2.119 GiB, 4.99% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.0601043   0.85288     0.0992113\n",
       "  0.85288    -0.0639196   0.106892 \n",
       "  0.0992113   0.106892   -0.0366838"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned5 = learn_glauber_dynamics_sgd(samples_T, RISE(), 8.0, 1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RISE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14.826829 seconds (287.32 M allocations: 5.145 GiB, 4.95% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.0612704   0.860571    0.0952477\n",
       "  0.860571   -0.0421665   0.105183 \n",
       "  0.0952477   0.105183   -0.0320085"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned5 = learn_glauber_dynamics_sgd(samples_T, RISE(), 8.0, 1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RPLE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.318468 seconds (19.04 M allocations: 349.709 MiB, 4.17% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.0443964   0.848512    0.101827 \n",
       "  0.848512   -0.0369464   0.108831 \n",
       "  0.101827    0.108831   -0.0518408"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned5 = learn_glauber_dynamics_sgd(samples_T, RPLE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing stochastic gradient solver for RPLE\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.092684 seconds (111.45 M allocations: 1.969 GiB, 4.75% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " -0.0456916   0.868695    0.0953161\n",
       "  0.868695   -0.0434767   0.103668 \n",
       "  0.0953161   0.103668   -0.0405221"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned5 = learn_glauber_dynamics_sgd(samples_T, RPLE(), 8.0, 1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning on correlated samples -- M-regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mRecompiling stale cache file /home/local/.julia/lib/v0.6/GraphicalModelLearning.ji for module GraphicalModelLearning.\n",
      "\u001b[39m\n",
      "WARNING: deprecated syntax \"inner constructor FactorGraph(...) around /home/local/Research/Code/GraphicalModelLearning.jl/src/models.jl:13\".\n",
      "Use \"FactorGraph{T}(...) where T\" instead.\n",
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36massuming spin alphabet\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36musing Glauber dynamics v1 to generate M-regime samples\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done sampling"
     ]
    }
   ],
   "source": [
    "using GraphicalModelLearning\n",
    "\n",
    "srand(0)\n",
    "\n",
    "# Define Graphical Model\n",
    "model = FactorGraph([0.0 0.9 0.1; 0.9 0.0 0.1; 0.1 0.1 0.0])\n",
    "#model = FactorGraph([0.4 0.9 0.1; 0.9 0.4 0.1; 0.1 0.1 0.4])\n",
    "\n",
    "n_samples = 5000\n",
    "# Plain sampling\n",
    "samples1 = sample(model, n_samples)\n",
    "\n",
    "# Gibbs Samples\n",
    "samples_M, samples_mixed = gibbs_sampling(model, n_samples, M_regime())\n",
    "#gibbs_output = gibbs_sampling(model, n_samples, T_regime())\n",
    "#samples_T = gibbs_output[1]\n",
    "#samples_mixed = gibbs_output[2]\n",
    "print(\"Done sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×7 Array{Int64,2}:\n",
       " 199   1  -1  -1  -1  -1  -1\n",
       "  23   1   1   1   1  -1   1\n",
       " 175  -1   1   1  -1   1   1\n",
       "  69  -1  -1  -1  -1  -1   1\n",
       "  93  -1   1  -1  -1   1   1\n",
       " 168  -1   1  -1  -1  -1  -1\n",
       "  23  -1  -1  -1  -1   1  -1\n",
       " 179  -1   1   1   1   1   1\n",
       "  47   1   1  -1   1  -1  -1\n",
       " 501  -1  -1  -1  -1  -1  -1\n",
       " 168   1  -1  -1   1  -1  -1\n",
       " 182   1  -1  -1   1   1  -1\n",
       " 168  -1   1  -1   1   1  -1\n",
       "   ⋮                   ⋮    \n",
       " 178   1  -1   1  -1  -1   1\n",
       " 160   1  -1   1   1   1   1\n",
       " 161  -1   1   1  -1  -1   1\n",
       " 176   1  -1   1   1  -1   1\n",
       " 513   1   1   1   1   1   1\n",
       " 114   1  -1   1   1  -1  -1\n",
       "  88   1   1   1   1   1  -1\n",
       " 417   1   1  -1   1   1  -1\n",
       " 429  -1  -1   1  -1  -1   1\n",
       "  91   1  -1  -1   1  -1   1\n",
       "  36  -1  -1   1  -1   1   1\n",
       " 166  -1   1  -1  -1   1  -1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×4 Array{Int64,2}:\n",
       " 1006  -1  -1  -1\n",
       "  837  -1  -1   1\n",
       "  980   1   1   1\n",
       "  320  -1   1  -1\n",
       "  855   1   1  -1\n",
       "  329   1  -1   1\n",
       "  322  -1   1   1\n",
       "  351   1  -1  -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "  8.998982 seconds (5.16 M allocations: 259.507 MiB, 0.95% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.00892352   0.232999    0.0100643\n",
       " 0.232999    -0.0132189   0.0210828\n",
       " 0.0100643    0.0210828  -0.0126277"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned1 = learn_glauber_dynamics(samples_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.265190 seconds (70.67 k allocations: 3.558 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3×3 Array{Float64,2}:\n",
       " 0.0132895   0.496226    0.0197846\n",
       " 0.496226   -0.0148107   0.0374478\n",
       " 0.0197846   0.0374478  -0.012612 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time learned2 = learn(samples_mixed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
